# Evaluation Framework for Spanish Medical Applications of Large Language Models

---
**ðŸ’¡ Note:**

> A new version of the Model Evaluator is currently under development, featuring:
>
> * Questions from the 2025 MIR exams.
> * Evaluation of the latest AI models.
> * Expanded testing of diverse prompting strategies.
> * Extension of the evaluation framework to other life-sciences knowledge domains.
> * Enhanced metadata and results analysis.
> * Improved visualization of evaluation outcomes.
>
> Track the progress of the ongoing 2025 evaluation here: [https://github.com/armelida/MELIDA](https://github.com/armelida/MELIDA)

---

## Overview
This repository contains all relevant documentation and code for the Master's Thesis by **Alberto RamÃ³n MÃ©lida Asensio** at **Universidad Internacional de La Rioja (UNIR)**. The thesis focuses on evaluating Large Language Models (LLMs) for **medical applications in Spanish**, particularly through an automated pipeline using **MIR exam questions**.

## Contents
- **SUMMARY.md**: Overview of the research, methodology, and key findings.
- **CODE/**: Python scripts for running the evaluation pipeline.
- **DATA/**: Dataset used for the evaluation (if applicable).
- **RESULTS/**: Evaluation results from different models.
- **REFERENCES.md**: Bibliography and citations.
- **LICENSE.md**: Licensing information for this project.

## Installation
To use this repository, follow these steps:

1. Clone the repository:
   ```sh
   git clone https://github.com/yourusername/TFM_GitHub.git
   cd TFM_GitHub
   ```
2. Install the required dependencies:
   ```sh
   pip install -r requirements.txt
   ```
3. Run the evaluation pipeline:
   ```sh
   python CODE/evaluation_pipeline.py
   ```

## Project Structure
```
TFM_GitHub/
â”‚â”€â”€ README.md                 # General overview of the project
â”‚â”€â”€ SUMMARY.md                # Summary of the TFM with key findings
â”‚â”€â”€ CODE/                     # Folder for scripts and relevant code
â”‚   â”œâ”€â”€ evaluation_pipeline.py  # Main evaluation script
â”‚   â”œâ”€â”€ data_preprocessing.py   # Data preparation script
â”‚   â””â”€â”€ model_analysis.py       # Post-processing results
â”‚â”€â”€ DATA/                      # Folder for datasets
â”‚â”€â”€ RESULTS/                   # Folder for evaluation results
â”‚â”€â”€ REFERENCES.md              # Bibliography and citations
â”‚â”€â”€ LICENSE.md                 # License information
â”‚â”€â”€ requirements.txt           # Dependencies required to run the project
```

## How to Contribute
Contributions are welcome! To contribute:
1. Fork the repository.
2. Create a new branch (`git checkout -b feature-branch`).
3. Commit your changes (`git commit -m 'Add new feature'`).
4. Push to the branch (`git push origin feature-branch`).
5. Open a Pull Request.

## Contact
For any inquiries, feel free to contact alberto@melida.eu or open an issue in this repository.

---
