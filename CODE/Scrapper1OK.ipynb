{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXfIr_io5rGE",
        "outputId": "da084ca7-8780-4664-e6f3-6103a0c2d87b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Starting downloads...\n",
            "Processing content...\n",
            "Download and processing complete!\n"
          ]
        }
      ],
      "source": [
        "# First install required packages\n",
        "!pip install -q requests beautifulsoup4 pandas\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "from urllib.parse import urljoin\n",
        "import json\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import re\n",
        "from typing import List, Dict\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class MedicalSourceDownloader:\n",
        "    def __init__(self, base_dir: str = '/content/drive/MyDrive/TFM2/medical_knowledge'):\n",
        "        \"\"\"\n",
        "        Initialize the downloader with sources and configurations\n",
        "        \"\"\"\n",
        "        self.base_dir = base_dir\n",
        "        self.session = requests.Session()\n",
        "        self.session.headers.update({\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "        })\n",
        "\n",
        "        # Create directories\n",
        "        os.makedirs(base_dir, exist_ok=True)\n",
        "        for subdir in ['raw', 'processed', 'metadata']:\n",
        "            os.makedirs(os.path.join(base_dir, subdir), exist_ok=True)\n",
        "\n",
        "        # Source definitions\n",
        "        self.sources = {\n",
        "            'medlineplus': {\n",
        "                'base_url': 'https://medlineplus.gov/spanish/',\n",
        "                'topics_url': 'https://medlineplus.gov/spanish/healthtopics.html',\n",
        "                'description': 'NIH Medical Encyclopedia in Spanish. High-quality, verified medical information.'\n",
        "            },\n",
        "            'fisterra': {\n",
        "                'base_url': 'https://www.fisterra.com/material-educacion-pacientes/',\n",
        "                'description': 'Spanish clinical practice guidelines and patient education materials.'\n",
        "            },\n",
        "            'scielo': {\n",
        "                'base_url': 'https://scielo.isciii.es/scielo.php',\n",
        "                'search_url': 'https://scielo.isciii.es/cgi-bin/wxis.exe/iah/',\n",
        "                'description': 'Scientific Electronic Library Online - Spanish medical journal articles.'\n",
        "            },\n",
        "            'mscbs': {\n",
        "                'base_url': 'https://www.sanidad.gob.es/profesionales/biblioteca/',\n",
        "                'description': 'Spanish Ministry of Health library resources.'\n",
        "            }\n",
        "        }\n",
        "\n",
        "    def download_medlineplus_topics(self):\n",
        "        \"\"\"\n",
        "        Download health topics from MedlinePlus en Español\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting MedlinePlus download...\")\n",
        "        try:\n",
        "            response = self.session.get(self.sources['medlineplus']['topics_url'])\n",
        "            response.raise_for_status()\n",
        "\n",
        "            soup = BeautifulSoup(response.text, 'html.parser')\n",
        "            topics_dir = os.path.join(self.base_dir, 'raw', 'medlineplus')\n",
        "            os.makedirs(topics_dir, exist_ok=True)\n",
        "\n",
        "            # Find and process topics\n",
        "            for link in soup.find_all('a', href=True):\n",
        "                if '/spanish/' in link['href'] and 'healthtopics' not in link['href']:\n",
        "                    try:\n",
        "                        topic_name = link.text.strip()\n",
        "                        topic_url = urljoin(self.sources['medlineplus']['base_url'], link['href'])\n",
        "                        filename = f\"{topic_name.replace(' ', '_')}.txt\"\n",
        "\n",
        "                        # Download topic content\n",
        "                        topic_response = self.session.get(topic_url)\n",
        "                        topic_soup = BeautifulSoup(topic_response.text, 'html.parser')\n",
        "                        content = topic_soup.find('div', {'id': 'topic-summary'})\n",
        "\n",
        "                        if content:\n",
        "                            with open(os.path.join(topics_dir, filename), 'w', encoding='utf-8') as f:\n",
        "                                f.write(f\"Title: {topic_name}\\nSource: MedlinePlus\\nURL: {topic_url}\\n\\n\")\n",
        "                                f.write(content.get_text(separator='\\n\\n', strip=True))\n",
        "                            logger.info(f\"Downloaded: {topic_name}\")\n",
        "\n",
        "                        time.sleep(2)  # Be respectful to the server\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error downloading topic {topic_name}: {str(e)}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            logger.error(f\"Error in MedlinePlus download: {str(e)}\")\n",
        "\n",
        "    def download_scielo_articles(self, search_terms: List[str]):\n",
        "        \"\"\"\n",
        "        Download medical articles from SciELO\n",
        "        \"\"\"\n",
        "        logger.info(\"Starting SciELO download...\")\n",
        "        articles_dir = os.path.join(self.base_dir, 'raw', 'scielo')\n",
        "        os.makedirs(articles_dir, exist_ok=True)\n",
        "\n",
        "        for term in search_terms:\n",
        "            try:\n",
        "                # Format search URL\n",
        "                search_url = f\"{self.sources['scielo']['search_url']}?IsisScript=iah/iah.xis&base=article^dlibrary&lang=e&nextAction=lnk&exprSearch={term}&indexSearch=TX\"\n",
        "                response = self.session.get(search_url)\n",
        "                response.raise_for_status()\n",
        "\n",
        "                soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "                # Find and process articles\n",
        "                for article in soup.find_all('div', class_='article'):\n",
        "                    try:\n",
        "                        title = article.find('h2').text.strip()\n",
        "                        abstract = article.find('div', class_='abstract').text.strip()\n",
        "\n",
        "                        filename = f\"scielo_{term}_{title[:50]}.txt\"\n",
        "                        with open(os.path.join(articles_dir, filename), 'w', encoding='utf-8') as f:\n",
        "                            f.write(f\"Title: {title}\\nSource: SciELO\\nTerm: {term}\\n\\n\")\n",
        "                            f.write(abstract)\n",
        "\n",
        "                        logger.info(f\"Downloaded article: {title[:50]}...\")\n",
        "                        time.sleep(2)\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error processing article: {str(e)}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                logger.error(f\"Error in SciELO search for term {term}: {str(e)}\")\n",
        "\n",
        "    def process_downloaded_content(self):\n",
        "        \"\"\"\n",
        "        Process and organize downloaded content\n",
        "        \"\"\"\n",
        "        logger.info(\"Processing downloaded content...\")\n",
        "\n",
        "        categories = {\n",
        "            'anatomia': ['anatomía', 'músculo', 'hueso', 'articulación', 'estructura'],\n",
        "            'fisiologia': ['fisiología', 'función', 'sistema', 'regulación', 'homeostasis'],\n",
        "            'patologia': ['patología', 'enfermedad', 'síndrome', 'trastorno', 'condición'],\n",
        "            'farmacologia': ['fármaco', 'medicamento', 'tratamiento', 'terapia', 'dosis'],\n",
        "            'diagnostico': ['diagnóstico', 'síntoma', 'signo', 'prueba', 'evaluación']\n",
        "        }\n",
        "\n",
        "        processed_dir = os.path.join(self.base_dir, 'processed')\n",
        "        for category in categories:\n",
        "            os.makedirs(os.path.join(processed_dir, category), exist_ok=True)\n",
        "\n",
        "        # Process each file in raw directory\n",
        "        for source_dir in os.listdir(os.path.join(self.base_dir, 'raw')):\n",
        "            source_path = os.path.join(self.base_dir, 'raw', source_dir)\n",
        "            if os.path.isdir(source_path):\n",
        "                for filename in os.listdir(source_path):\n",
        "                    try:\n",
        "                        with open(os.path.join(source_path, filename), 'r', encoding='utf-8') as f:\n",
        "                            content = f.read().lower()\n",
        "\n",
        "                        # Determine best category\n",
        "                        max_matches = 0\n",
        "                        best_category = 'otros'\n",
        "                        for category, keywords in categories.items():\n",
        "                            matches = sum(1 for keyword in keywords if keyword in content)\n",
        "                            if matches > max_matches:\n",
        "                                max_matches = matches\n",
        "                                best_category = category\n",
        "\n",
        "                        # Copy to processed directory with category\n",
        "                        with open(os.path.join(processed_dir, best_category, filename), 'w', encoding='utf-8') as f:\n",
        "                            f.write(content)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        logger.error(f\"Error processing file {filename}: {str(e)}\")\n",
        "\n",
        "        logger.info(\"Content processing complete!\")\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define search terms\n",
        "search_terms = [\n",
        "    'sistema renina angiotensina',\n",
        "    'metabolismo hierro',\n",
        "    'diabetes mellitus',\n",
        "    'anatomia rotadores',\n",
        "    'fisiologia esofago'\n",
        "]\n",
        "\n",
        "# Create downloader instance\n",
        "downloader = MedicalSourceDownloader()\n",
        "\n",
        "# Run downloads\n",
        "print(\"Starting downloads...\")\n",
        "downloader.download_medlineplus_topics()\n",
        "downloader.download_scielo_articles(search_terms)\n",
        "\n",
        "# Process content\n",
        "print(\"Processing content...\")\n",
        "downloader.process_downloaded_content()\n",
        "\n",
        "print(\"Download and processing complete!\")"
      ]
    }
  ]
}